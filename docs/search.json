[
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Below is a list of research articles, reports, and publications that have utilized GLOSSA for species distribution modeling.\n\n\n\n\n\nFuster-Alonso, A., Mestre-Tomás, J., Baez, J. C., Pennino, M. G., Barber, X., Bellido, J. M., … & Coll, M. (2024). Machine learning applied to global scale species distribution models (SDMs). PREPRINT (Version 1) available at Research Square. doi: https://doi.org/10.21203/rs.3.rs-4411399/v1\n\n\n\n\n\nHave you used GLOSSA in your research? We’d love to feature your publication here! Please contact us with the details of your work."
  },
  {
    "objectID": "publications.html#full-list-of-publications",
    "href": "publications.html#full-list-of-publications",
    "title": "Publications",
    "section": "",
    "text": "Fuster-Alonso, A., Mestre-Tomás, J., Baez, J. C., Pennino, M. G., Barber, X., Bellido, J. M., … & Coll, M. (2024). Machine learning applied to global scale species distribution models (SDMs). PREPRINT (Version 1) available at Research Square. doi: https://doi.org/10.21203/rs.3.rs-4411399/v1"
  },
  {
    "objectID": "publications.html#submit-a-publication",
    "href": "publications.html#submit-a-publication",
    "title": "Publications",
    "section": "",
    "text": "Have you used GLOSSA in your research? We’d love to feature your publication here! Please contact us with the details of your work."
  },
  {
    "objectID": "pages/guide/index.html",
    "href": "pages/guide/index.html",
    "title": "GLOSSA Documentation - Coming Soon!",
    "section": "",
    "text": "Our team is hard at work to provide you with comprehensive guides and resources.\nThank you for your patience. Stay tuned for updates!"
  },
  {
    "objectID": "how_to_cite.html",
    "href": "how_to_cite.html",
    "title": "How to cite GLOSSA",
    "section": "",
    "text": "How to cite GLOSSA\nThank you for using GLOSSA! Tu cite our app, please use the following references.\n\nGLOSSA GitHub repository\nThe GLOSSA paper is currently in progress. Meanwhile, you can reference the GitHub repository as follows:\n\nMestre-Tomás, J., Fuster-Alonso, A., & Coll, M. (2024) GLOSSA: A user-friendly Shiny app for global spatiotemporal analysis of species with BART machine learning model. R package version 0.1.0, https://github.com/jmestret/glossa\n\n\n\nBART model reference\nIf you use the BART model in your work, please also cite the original paper:\n\nChipman, H. A., George, E. I., & McCulloch, R. E. (2010). BART: Bayesian Additive Regression Trees. The Annals of Applied Statistics, 4(1), 266–298. doi: https://doi.org/10.1214/09-AOAS285\n\nand if use BART on a global-scale, please include this citation:\n\nFuster-Alonso, A., Mestre-Tomás, J., Baez, J. C., Pennino, M. G., Barber, X., Bellido, J. M., … & Coll, M. (2024). Machine learning applied to global scale species distribution models (SDMs). PREPRINT (Version 1) available at Research Square^. doi: https://doi.org/10.21203/rs.3.rs-4411399/v1."
  },
  {
    "objectID": "get_started.html",
    "href": "get_started.html",
    "title": "Get started",
    "section": "",
    "text": "Welcome to GLOSSA, our Shiny app for species distribution modeling! This tool allows you to predict species distributions using occurrence data and environmental data. Below is a quick guide to help you get started. Please ensure that you have R version 4.0.0 or higher installed before proceeding:"
  },
  {
    "objectID": "get_started.html#installation",
    "href": "get_started.html#installation",
    "title": "Get started",
    "section": "Installation",
    "text": "Installation\nTo install the GLOSSA shiny app, run the following command in your R console:\ninstall.packages(\"glossa\")\nAlternatively, you can install the latest development version from GitHub to get the newest updates and fixes:\nif (!require(\"devtools\")) \n  install.packages(\"devtools\")\n\ndevtools::install_github(\"jmestret/glossa\")"
  },
  {
    "objectID": "get_started.html#glossa-workflow-summary",
    "href": "get_started.html#glossa-workflow-summary",
    "title": "Get started",
    "section": "GLOSSA workflow summary",
    "text": "GLOSSA workflow summary\n\nData input:\n\nLoad species occurrence data: Upload species occurrence data, either presence-absence or presence-only (with pseudo-absences generated). Multiple species can be modeled in one session.\nUpload environmental data: Provide environmental variables in raster format, used as predictors in the model. These layers also define the study area unless a polygon is provided.\nUpload projection layers: Optionally, upload layers to forecast for different time periods or climate scenarios.\nDefine study area: Optionally, upload a polygon to define the study area, which will filter occurrences and crop environmental layers.\n\nData processing:\n\nCoordinate cleaning: GLOSSA cleans coordinates by removing duplicates and points outside the study area.\nLayers processing: Environmental layers are cropped, masked, and optionally standardized using Z-score.\nGenerate pseudo-absences: For presence-only data, pseudo-absences are randomly generated.\n\nModel fitting and Pprediction:\n\nFit BART model: Two models are fitted—one based on environmental data and another including spatial smoothing.\nModel output: Predict species occurrence probabilities and determine optimal classification cutoffs. Evaluate predictive performance using cross-validation, and assess variable importance and functional responses.\nProjections: Generate projections for different areas, time periods, and climate scenarios using the Bayesian framework.\n\nVisualization and export:\n\nExplore and save interactive results once the analysis is complete."
  },
  {
    "objectID": "get_started.html#quick-start-guide",
    "href": "get_started.html#quick-start-guide",
    "title": "Get started",
    "section": "Quick start guide",
    "text": "Quick start guide\nHere’s a quick guide on how to use the app. First, launch the app by running the run_glossa() function:\nlibrary(glossa)\nrun_glossa()\nThis will open the app on the Home tab, the landing page of the app. From here, you can start a new analysis, watch our demo video, explore the documentation, read tutorials, or even meet the team that built the app!\n\n\n\n\n\nClicking on the question mark icon  on the top right corner will bring up a brief explanation of what each tab and button does.\n\n\n\n\n\n\nSidebar overview\nOn the sidebar, you’ll find two main sections: Modelling and Resources.\n\nResources: This section provides essential information to help you run the app. It’s a great place to refresh your knowledge, especially if it’s been a while since you last used GLOSSA. Note that the full documentation is hosted outside the app in this website.\nModelling: This section includes the New Analysis, Reports, and Exports tabs. Typically, you’ll go through these tabs in sequence:\n\nNew Analysis: Set up your analysis, upload your data, and select analysis options.\nReports: Explore the results and visualizations generated by the analysis.\nExports: Download the results for further use."
  },
  {
    "objectID": "get_started.html#running-your-first-analysis",
    "href": "get_started.html#running-your-first-analysis",
    "title": "Get started",
    "section": "Running your first analysis",
    "text": "Running your first analysis\nTo run your first analysis, go to the New Analysis tab. This tab looks like this:\n\n\n\n\n\nHere, you need to upload the required input files and select your analysis options:\n\nData upload: The first panel is where you upload your data and configure the analysis settings.\nPrevisualization: The second panel provides an interactive map to preview your input data.\nPredictor variables: Choose predictor variables for each uploaded species.\nUploaded files: A table indicates if your input files are formatted correctly.\n\n\nRequired files for analysis\nGLOSSA can function with just occurrence data and environmental variables, but additional options are available. Let’s briefly go through the necessary files:\n\nOccurrences: Upload a tab-separated CSV file with four columns indicating the occurrence location, whether it is a presence or absence, and the time it was recorded. The columns must be named exactly as follows: decimalLongitude, decimalLatitude, pa, and timestamp. If the pa column is missing, GLOSSA will assume all rows are presences. If timestamp is missing, GLOSSA will assume all observations occurred at the same time. GLOSSA also supports presence-only data but will generate randomly distributed balanced pseudo-absences to fit the model.\n&gt; head(sp1)\n  decimalLongitude decimalLatitude timestamp pa\n1          5.42909        43.20937         1  1\n2           -43.05           49.03         1  0\n3         -2.52369        47.29234         2  1\n4           34.054         -26.913         2  1\n5           -41.63            46.3         2  0\n6           -174.5            27.5         3  1\nEnvironmental data: Upload environmental data as raster files (e.g., .tif or .nc format) in a ZIP file with a specific structure. The ZIP file should contain a subdirectory for each environmental variable, with files sorted by time period. For example, if you have two variables (x1 and x2) and your observations are from two different years, your ZIP file should look like this:\nfit_layers.zip\n    ├───x1\n    │       x1_1.tif\n    │       x1_2.tif\n    └───x2\n            x2_1.tif\n            x2_2.tif\nEnsure that all layers have the same resolution, the same number of layers, and that they match the number of years in your occurrence files. If you want to use the same layer for all observations, include just one file in the subdirectory and set all timestamp values to 1 or remove the timestamp column.\nProjection layers (Optional): If you want to make predictions, upload your projection data here. This file has the same format as the environmental data file, and the subdirectories must match those used for fitting the model. You can upload multiple ZIP files if you want to predict multiple scenarios (e.g., different temperature increase scenarios).\nStudy area (Optional): If your rasters cover a larger area than your study region, you can provide a polygon to delimit your study area (formats: GPKG, KML or GeoJSON). This will remove points outside the polygon and mask the environmental variables accordingly.\n\nOnce all files are uploaded, if they pass the checks and are properly formatted, the table in the bottom right panel will show a checkmark for each file. If something is incorrect, refer to the documentation for a quick solution.\n\n\nAnalysis options\nIn this section, you need to select the desired output. GLOSSA fits two kinds of models:\n\nNative range: The model includes environmental variables and uses longitude and latitude coordinates as a spatial smoother.\nSuitable habitat: The model only includes the environmental variables.\n\nYou can choose to fit the model under the Model fitting option. This option will fit the model, compute variable importance, and generate a prediction map representing the mean environmental conditions across all provided layers. If you’ve uploaded projection layers and want to make predictions using the fitted model, select the Model projection option.\nWhen fitting the model, if multiple years or time periods are uploaded, GLOSSA will extract the value of the corresponding environmental layer for each occurrence based on the specific time stamp.\nAdditionally, you can check the Functional responses checkbox if you want to compute the response curves (i.e., the relationship between the occurrence of a species and each environmental variable). You can also enable Cross-validation, which will perform a K-fold cross-validation with (k = 5).\n\n\nAdvanced options\nBy selecting the Advanced options button, a sidebar will appear with extra options for refining your analysis:\n\nOccurrences thinning: Specify the number of decimal places to round coordinates, allowing you to apply spatial thinning to your occurrence data using a precision-based method. GLOSSA currently implements this method via the GeoThinneR R package, which is the most time- and memory-efficient option for large datasets. If you need to perform spatial thinning based on distance or a grid, you can do so before uploading your data to GLOSSA using GeoThinneR or other methods.\nStandardize covariates: GLOSSA uses a scaling method that subtracts the mean and divides by the standard deviation for standardization. The mean and standard deviation are calculated from the fitting layers, and the same values are used to standardize the projection layers, ensuring consistency across variables.\nEnlarge polygon: If your polygon has low resolution, you can apply a buffer in degrees to expand it. This is useful if you have points near the coast that fall outside the polygon due to poor resolution. You can preview the buffer using the “play” icon before running the analysis to find the optimal value.\nModel: Choose the model to apply. Currently, GLOSSA only supports the BART model, so no additional selection is needed here.\nSet a seed: Specify a seed for reproducibility of your results.\n\n\n\n\n\n\n\n\nPredictor variables\nIf you uploaded multiple species, you can select different predictor variables for each species in the bottom left panel.\n\n\n\n\n\n\n\nUploaded files\nIn the table in the bottom right corner, ensure that all files are checked and that you’ve selected your analysis options.\n\n\n\n\n\nOnce everything is set, you’re ready to run the analysis. Click the Run Job button, confirm in the dialog, and wait for the analysis to complete."
  },
  {
    "objectID": "get_started.html#analysis-results",
    "href": "get_started.html#analysis-results",
    "title": "Get started",
    "section": "Analysis results",
    "text": "Analysis results\nOnce the analysis is complete, you will be redirected to the Reports tab, where you can explore all the results and export visualizations .\n\n\n\n\n\nIn the top left corner of the tab, you can select the species for which you want to view the results. The first row displays key metrics:\n\nPotential suitable area: Calculated in square kilometers, based on the predicted presence-absence grid cells.\nMean suitable probability: The average probability of suitable habitat across the entire prediction area.\nPresences/Absences: The number of presence and absence points used to fit the model after all processing and cleaning.\n\nIf multiple projection layers are provided (for example, a time series), a sparkline plot will display the values for each time period, and the text value shown will represent the last one in the time series.\n\nGLOSSA predictions\nThe first plot, titled GLOSSA predictions, shows the presence probability predictions within the study area. As we are working in the Bayesian framework, each grid cell has associated one predictive posterior distribution, therefore we can obtain a more comprenhensive undertanding of the predictions by exploring metrics like the mean, median or quantiles. Using the three-dot icon , you can open the sidebar to customize the display:\n\nChoose between predictions on the fitting layers or the projection layers.\nToggle between viewing the native range or the suitable habitat.\nSelect which value from the posterior distribution to display (e.g., mean probability, median, etc.).\n\n\n\n\n\n\n\n\nEnvironmental variables and Presence validation\nThe plot on the right shows the environmental variables used to fit the model, allowing you to quickly compare them with the probability projections. Below this, another plot displays the occurrence points that were retained or filtered out during the analysis.\n\n\n\n\n\n\n\nFunctional responses and Variable importance\nIn the last row, you can view:\n\nFunctional response: These illustrate the relationship between each environmental variable and the predicted suitable habitat (response curves).\nVariable importance: Displays the importance of each variable for both the native range and the suitable habitat.\n\n\n\n\n\n\n\n\nCross-validation\nIn the cross-validation panel, you’ll find performance metrics such as:\n\nAIC (Akaike Information Criterion)\nRMSE (Root Mean Square Error)\n5-Fold Cross-Validation Results"
  },
  {
    "objectID": "get_started.html#exports",
    "href": "get_started.html#exports",
    "title": "Get started",
    "section": "Exports",
    "text": "Exports\nIn the Exports tab, you can export the results of your analysis. This includes all projection maps, the data used to fit the model, variable importance metrics, cross-validation results, etc. You can export almost everything, enabling you to explore the results further or create your own visualizations for your work!"
  },
  {
    "objectID": "get_started.html#next-steps",
    "href": "get_started.html#next-steps",
    "title": "Get started",
    "section": "Next Steps",
    "text": "Next Steps\nThis Quick start guide for GLOSSA should help you get up and running. For more detailed instructions, check out the Tutorial tab, where you’ll find tutorials on how to prepare your data for GLOSSA or even worked examples that guide you through using GLOSSA from end-to-end.\nAdditionally, the Documentation tab offers a comprehensive guide to every aspect of the GLOSSA app. Here, you’ll find not only in-depth information on how GLOSSA works but also tips and tricks to help you get the most out of the app.\nIf you have further questions, visit the FAQs tab, or if you still need help, you can reach us through the Contact Us tab.\nThank you for using GLOSSA, and enjoy your species distribution modeling!"
  },
  {
    "objectID": "contact_us.html",
    "href": "contact_us.html",
    "title": "Contact us",
    "section": "",
    "text": "We value your feedback and are here to help you with any questions, support needs or collaboration requests. Please use the following means to get in touch with us:\n\n\nFor issues, feature requests, questions, or general feedback, please use the Issues tab on our GitHub repository:\n\nGLOSSA GitHub\n\n\n\n\nFor special support or collaboration requests, please contact us via the contact form at the end of the iMARES website:\n\niMARES\n\n\n\n\nFollow our research group on Twitter for the latest news and updates:\n\n@iMARES_group\n\nThank you for your support! If you want to know more about the group go and visit our website: iMARES"
  },
  {
    "objectID": "contact_us.html#github",
    "href": "contact_us.html#github",
    "title": "Contact us",
    "section": "",
    "text": "For issues, feature requests, questions, or general feedback, please use the Issues tab on our GitHub repository:\n\nGLOSSA GitHub"
  },
  {
    "objectID": "contact_us.html#contact-form",
    "href": "contact_us.html#contact-form",
    "title": "Contact us",
    "section": "",
    "text": "For special support or collaboration requests, please contact us via the contact form at the end of the iMARES website:\n\niMARES"
  },
  {
    "objectID": "contact_us.html#x-twitter",
    "href": "contact_us.html#x-twitter",
    "title": "Contact us",
    "section": "",
    "text": "Follow our research group on Twitter for the latest news and updates:\n\n@iMARES_group\n\nThank you for your support! If you want to know more about the group go and visit our website: iMARES"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "course.html",
    "href": "course.html",
    "title": "We are working to provide teaching materials!",
    "section": "",
    "text": "Thank you for your patience. Stay tuned for updates!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GLOSSA Documentation - Coming Soon!",
    "section": "",
    "text": "Our team is hard at work to provide you with comprehensive guides and resources.\nThank you for your patience. Stay tuned for updates!"
  },
  {
    "objectID": "pages/input/index.html",
    "href": "pages/input/index.html",
    "title": "GLOSSA Documentation - Coming Soon!",
    "section": "",
    "text": "Our team is hard at work to provide you with comprehensive guides and resources.\nThank you for your patience. Stay tuned for updates!"
  }
]